<div align="center">

<!-- ANIMATED TYPING HEADER -->
<img src="https://readme-typing-svg.demolab.com?font=Fira+Code&weight=700&size=38&pause=1000&color=A78BFA&center=true&vCenter=true&width=900&height=80&lines=Statistics+%26+Probability+%F0%9F%94%AE;The+Math+Engine+of+Data+Science;Descriptive+%E2%86%92+Inferential+%E2%86%92+Hypothesis+Testing" alt="Typing SVG"/>

<img src="https://readme-typing-svg.demolab.com?font=Fira+Code&weight=400&size=17&pause=2000&color=7C3AED&center=true&vCenter=true&width=900&height=40&lines=WsCube+Tech+Data+Science+%7C+Module+14-15+%7C+30%2B+Concepts+%7C+12%2B+Notebooks" alt="Subtitle"/>

<br/>

<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%"/>

<br/>

<p>
  <img src="https://img.shields.io/badge/Module-Statistics%20%26%20Probability-7c3aed?style=for-the-badge&logo=python&logoColor=white"/>
  <img src="https://img.shields.io/badge/Course-WsCube%20Tech-a78bfa?style=for-the-badge&logo=youtube&logoColor=white"/>
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white"/>
  <img src="https://img.shields.io/badge/SciPy-8CAAE6?style=for-the-badge&logo=scipy&logoColor=white"/>
  <img src="https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy&logoColor=white"/>
</p>

<p>
  <img src="https://img.shields.io/badge/Notebooks-12%2B-success?style=flat-square"/>
  <img src="https://img.shields.io/badge/Concepts-30%2B-blueviolet?style=flat-square"/>
  <img src="https://img.shields.io/badge/Level-Beginner%20%E2%86%92%20Intermediate-orange?style=flat-square"/>
  <img src="https://img.shields.io/badge/Status-Active-brightgreen?style=flat-square"/>
  <img src="https://img.shields.io/github/last-commit/MuhammadZafran33/Data-Science-Course?style=flat-square&color=violet"/>
</p>

<br/>

> ### ğŸ¯ *"Statistics is the grammar of science"* â€” Karl Pearson
>
> Complete **Statistics & Probability** foundation required for Data Science â€”
> from central tendency all the way to hypothesis testing & distributions.

</div>

---

## ğŸ“š Table of Contents

| # | Section | Link |
|---|---------|------|
| 01 | ğŸ—ºï¸ Module Overview | [Jump](#ï¸-module-overview) |
| 02 | ğŸ§­ Learning Roadmap | [Jump](#-learning-roadmap) |
| 03 | ğŸ“– Topic Deep Dive | [Jump](#-topic-deep-dive) |
| 04 | ğŸ“Š Coverage Charts | [Jump](#-coverage-charts) |
| 05 | ğŸ”¬ Probability Distributions | [Jump](#-probability-distributions-at-a-glance) |
| 06 | ğŸ§ª Hypothesis Testing Guide | [Jump](#-hypothesis-testing-decision-guide) |
| 07 | ğŸ“ Formulas Cheatsheet | [Jump](#-key-formulas-cheatsheet) |
| 08 | ğŸ“ Folder Structure | [Jump](#-folder-structure) |
| 09 | ğŸ› ï¸ Tools & Libraries | [Jump](#ï¸-tools--libraries) |
| 10 | ğŸš€ Getting Started | [Jump](#-getting-started) |

---

## ğŸ—ºï¸ Module Overview

<div align="center">

| ğŸ“Œ Attribute | ğŸ“‹ Details |
|-------------|-----------|
| ğŸ“ **Parent Course** | Data Science Full Course â€” WsCube Tech |
| ğŸ“‚ **Module Name** | Statistics & Probability |
| ğŸ“ **Position** | Module 14â€“15 (Core DS Foundation) |
| â±ï¸ **Duration** | 2â€“3 Weeks Â· 15+ Hours |
| ğŸ““ **Notebooks** | 12+ Jupyter Notebooks |
| ğŸ¯ **Why It Matters** | Every ML algorithm is built on statistics |
| ğŸ”— **Leads To** | EDA â†’ Machine Learning â†’ Model Evaluation |

</div>

---

## ğŸ§­ Learning Roadmap

```mermaid
flowchart TD
    START(["ğŸ“Š START\nStatistics & Probability"])

    START --> A["ğŸ“Œ Introduction\nData Â· Sample Â· Population Â· Types of Data"]

    A --> B["ğŸ“ˆ Descriptive Statistics"]
    B --> B1["ğŸ“ Central Tendency\nMean Â· Median Â· Mode"]
    B --> B2["ğŸ“ Dispersion\nRange Â· Variance Â· Std Dev Â· IQR"]
    B --> B3["ğŸ”— Bivariate\nCovariance Â· Correlation"]

    B1 & B2 & B3 --> C["ğŸ² Probability Theory\nRandom Variables Â· PDF Â· CDF"]

    C --> D["ğŸ”” Distributions"]
    D --> D1["Normal"]
    D --> D2["Binomial"]
    D --> D3["Poisson"]

    D1 & D2 & D3 --> E["ğŸ“‰ Inferential Statistics"]
    E --> E1["ğŸ”„ Central Limit Theorem"]
    E --> E2["ğŸ“Š Skewness & Kurtosis"]

    E1 & E2 --> F["ğŸ§ª Hypothesis Testing"]
    F --> F1["âš¡ Z-Test"]
    F --> F2["ğŸ“ T-Test"]
    F --> F3["ğŸ”² Chi-Square"]

    F1 & F2 & F3 --> END(["âœ… COMPLETE\nReady for EDA & ML"])

    style START fill:#7c3aed,stroke:none,color:#fff
    style END fill:#059669,stroke:none,color:#fff
    style A fill:#1e1b4b,stroke:#7c3aed,color:#c4b5fd
    style B fill:#1e1b4b,stroke:#7c3aed,color:#c4b5fd
    style C fill:#1e1b4b,stroke:#a78bfa,color:#c4b5fd
    style D fill:#1e1b4b,stroke:#a78bfa,color:#c4b5fd
    style E fill:#1e1b4b,stroke:#7c3aed,color:#c4b5fd
    style F fill:#1e1b4b,stroke:#7c3aed,color:#c4b5fd
    style B1 fill:#2d1b69,stroke:none,color:#e9d5ff
    style B2 fill:#2d1b69,stroke:none,color:#e9d5ff
    style B3 fill:#2d1b69,stroke:none,color:#e9d5ff
    style C fill:#2d1b69,stroke:none,color:#e9d5ff
    style D1 fill:#4c1d95,stroke:none,color:#e9d5ff
    style D2 fill:#4c1d95,stroke:none,color:#e9d5ff
    style D3 fill:#4c1d95,stroke:none,color:#e9d5ff
    style E1 fill:#2d1b69,stroke:none,color:#e9d5ff
    style E2 fill:#2d1b69,stroke:none,color:#e9d5ff
    style F1 fill:#4c1d95,stroke:none,color:#e9d5ff
    style F2 fill:#4c1d95,stroke:none,color:#e9d5ff
    style F3 fill:#4c1d95,stroke:none,color:#e9d5ff
```

---

## ğŸ“– Topic Deep Dive

### ğŸ”· PART 1 â€” Descriptive Statistics

#### ğŸ“ Measures of Central Tendency

| Measure | Formula | Best Used When | Notebook |
|---------|---------|---------------|:--------:|
| **Mean** | `Î£x / n` | Symmetric data, no outliers | `02_central_tendency.ipynb` |
| **Median** | Middle value when sorted | Skewed data or outliers | `02_central_tendency.ipynb` |
| **Mode** | Most frequent value | Categorical data | `02_central_tendency.ipynb` |

#### ğŸ“ Measures of Dispersion

| Measure | Formula | What It Shows | Notebook |
|---------|---------|--------------|:--------:|
| **Range** | `Max âˆ’ Min` | Total spread | `03_dispersion.ipynb` |
| **Variance** | `Î£(xâˆ’Î¼)Â² / n` | Avg squared deviation from mean | `03_dispersion.ipynb` |
| **Std Dev** | `âˆšVariance` | Spread in original units | `03_dispersion.ipynb` |
| **IQR** | `Q3 âˆ’ Q1` | Middle 50% spread, outlier-robust | `03_dispersion.ipynb` |

#### ğŸ”— Bivariate Analysis

| Concept | Range | Interpretation | Notebook |
|---------|-------|---------------|:--------:|
| **Covariance** | `-âˆ to +âˆ` | Direction of linear relationship | `04_bivariate.ipynb` |
| **Pearson r** | `-1 to +1` | Strength + direction | `04_bivariate.ipynb` |

---

### ğŸ”· PART 2 â€” Probability & Distributions

| Concept | Key Idea | Notebook |
|---------|---------|:--------:|
| **Random Variable** | Value determined by random experiment | `05_probability.ipynb` |
| **PDF** | Probability for continuous variables | `05_probability.ipynb` |
| **CDF** | Probability that X â‰¤ x | `05_probability.ipynb` |
| **Normal Distribution** | Bell curve â€” most important distribution | `06_normal_dist.ipynb` |
| **Binomial Distribution** | Success/failure over n trials | `07_binomial_dist.ipynb` |
| **Poisson Distribution** | Count of events in a fixed interval | `08_poisson_dist.ipynb` |
| **Skewness** | Asymmetry of distribution around mean | `09_skewness.ipynb` |

---

### ğŸ”· PART 3 â€” Inferential Statistics & Hypothesis Testing

| Concept | Key Idea | Notebook |
|---------|---------|:--------:|
| **Central Limit Theorem** | Sample means â†’ normal regardless of population | `10_CLT.ipynb` |
| **Null Hypothesis Hâ‚€** | Default claim â€” no effect exists | `11_hypothesis.ipynb` |
| **Alternate Hypothesis Hâ‚** | What we aim to prove | `11_hypothesis.ipynb` |
| **p-value** | Probability of results if Hâ‚€ is true | `11_hypothesis.ipynb` |
| **Significance Level Î±** | Threshold (0.05) to reject Hâ‚€ | `11_hypothesis.ipynb` |
| **Confidence Interval** | Range containing true param with (1âˆ’Î±)% certainty | `11_hypothesis.ipynb` |
| **Z-Test** | Test mean when Ïƒ known, n â‰¥ 30 | `12_zttest.ipynb` |
| **T-Test** | Test mean when Ïƒ unknown or small n | `12_zttest.ipynb` |
| **Chi-Square Test** | Independence between categorical variables | `13_chi_square.ipynb` |

---

## ğŸ“Š Coverage Charts

```mermaid
pie title Statistics and Probability â€” Topic Coverage
    "Descriptive Statistics" : 25
    "Probability Theory" : 20
    "Probability Distributions" : 22
    "Inferential Statistics" : 15
    "Hypothesis Testing" : 18
```

```mermaid
xychart-beta
    title "Estimated Study Hours per Section"
    x-axis ["Intro", "Central Tendency", "Dispersion", "Bivariate", "Probability", "Distributions", "CLT", "Hypothesis Tests"]
    y-axis "Hours" 0 --> 4
    bar [1, 1.5, 2, 1.5, 2, 3, 2, 3]
```

```mermaid
gantt
    title Module Position in Full Course
    dateFormat  X
    axisFormat  Module %s

    section Python
    Python Fundamentals     :done, m1, 1, 5
    Web Scraping            :done, m2, 5, 6

    section Data Science
    Intro to Data Science   :done, m3, 6, 7
    Statistics and Prob     :active, m4, 7, 9

    section Data Layer
    NumPy                   :  m5, 9, 10
    Pandas                  :  m6, 10, 12

    section Visualization
    Matplotlib and Seaborn  :  m7, 12, 14

    section ML
    Machine Learning        :  m8, 14, 22
```

---

## ğŸ”¬ Probability Distributions at a Glance

```mermaid
flowchart LR
    subgraph DISCRETE ["ğŸ² Discrete Distributions"]
        direction TB
        B["ğŸ“Š Binomial\nBin(n,p)\nFixed trials, Success/Fail\nEx: Coin flips, A/B tests"]
        P["ğŸ“ˆ Poisson\nPois(Î»)\nEvents per interval\nEx: Calls per hour"]
    end

    subgraph CONTINUOUS ["ã€°ï¸ Continuous Distributions"]
        direction TB
        N["ğŸ”” Normal\nN(Î¼,ÏƒÂ²)\nBell curve\n68-95-99.7 Rule"]
        U["â¬œ Uniform\nU(a,b)\nEqual probability\nEx: Random numbers"]
    end

    style B fill:#4c1d95,stroke:none,color:#e9d5ff
    style P fill:#4c1d95,stroke:none,color:#e9d5ff
    style N fill:#1e1b4b,stroke:#7c3aed,color:#c4b5fd
    style U fill:#1e1b4b,stroke:#7c3aed,color:#c4b5fd
```

### Distribution Properties Table

| Distribution | Type | Parameters | Mean | Variance | Real-World Use |
|-------------|------|-----------|------|----------|----------------|
| ğŸ”” **Normal** | Continuous | Î¼, Ïƒ | Î¼ | ÏƒÂ² | Heights, test scores, measurement error |
| ğŸ“Š **Binomial** | Discrete | n, p | np | np(1âˆ’p) | Coin flips, pass/fail, click-through rates |
| ğŸ“ˆ **Poisson** | Discrete | Î» | Î» | Î» | Calls/hour, bugs/file, accidents/day |
| â¬œ **Uniform** | Continuous | a, b | (a+b)/2 | (bâˆ’a)Â²/12 | Random number generation |

---

## ğŸ§ª Hypothesis Testing Decision Guide

```mermaid
flowchart TD
    A(["ğŸ§ª What do you want to test?"]) --> B{"Data type?"}

    B -- "Numerical means" --> C{"How many groups?"}
    B -- "Categorical frequencies" --> G["ğŸ”² Chi-Square Test"]

    C -- "1 group vs known Î¼" --> D{"Ïƒ known & nâ‰¥30?"}
    C -- "2 independent groups" --> E["ğŸ“ Two-Sample T-Test"]
    C -- "Before & after, same group" --> F["ğŸ“ Paired T-Test"]

    D -- "YES" --> H["âš¡ One-Sample Z-Test"]
    D -- "NO" --> I["ğŸ“ One-Sample T-Test"]

    H & I & E & F & G --> J(["Compute p-value"])

    J --> K{"p-value < Î± (0.05)?"}
    K -- "YES âœ…" --> L(["âœ… Reject Hâ‚€\nStatistically Significant"])
    K -- "NO âŒ" --> M(["âŒ Fail to Reject Hâ‚€\nInsufficient Evidence"])

    style A fill:#7c3aed,stroke:none,color:#fff
    style L fill:#059669,stroke:none,color:#fff
    style M fill:#dc2626,stroke:none,color:#fff
    style J fill:#1e1b4b,stroke:#7c3aed,color:#c4b5fd
    style K fill:#4c1d95,stroke:none,color:#e9d5ff
    style B fill:#2d1b69,stroke:none,color:#e9d5ff
    style C fill:#2d1b69,stroke:none,color:#e9d5ff
    style D fill:#2d1b69,stroke:none,color:#e9d5ff
    style E fill:#1e1b4b,stroke:#a78bfa,color:#c4b5fd
    style F fill:#1e1b4b,stroke:#a78bfa,color:#c4b5fd
    style G fill:#1e1b4b,stroke:#a78bfa,color:#c4b5fd
    style H fill:#1e1b4b,stroke:#a78bfa,color:#c4b5fd
    style I fill:#1e1b4b,stroke:#a78bfa,color:#c4b5fd
```

### Tests Quick-Reference

| Test | Use Case | Condition | Python Function |
|------|---------|-----------|----------------|
| âš¡ **Z-Test** | 1 mean vs known Î¼ | Ïƒ known, n â‰¥ 30 | `statsmodels.stats.weightstats.ztest` |
| ğŸ“ **1-Sample T** | 1 mean vs value | Ïƒ unknown / small n | `scipy.stats.ttest_1samp` |
| ğŸ“ **2-Sample T** | Compare two groups | Independent | `scipy.stats.ttest_ind` |
| ğŸ“ **Paired T** | Before vs after | Same group | `scipy.stats.ttest_rel` |
| ğŸ”² **Chi-Square** | Categorical association | Expected freq â‰¥ 5 | `scipy.stats.chi2_contingency` |

---

## ğŸ“ Key Formulas Cheatsheet

<div align="center">

| ğŸ“Œ Concept | ğŸ”¢ Formula |
|-----------|-----------|
| **Population Mean** | `Î¼ = Î£xáµ¢ / N` |
| **Sample Mean** | `xÌ„ = Î£xáµ¢ / n` |
| **Population Variance** | `ÏƒÂ² = Î£(xáµ¢ âˆ’ Î¼)Â² / N` |
| **Sample Variance** | `sÂ² = Î£(xáµ¢ âˆ’ xÌ„)Â² / (nâˆ’1)` |
| **Standard Deviation** | `Ïƒ = âˆšÏƒÂ²` |
| **Z-Score** | `z = (x âˆ’ Î¼) / Ïƒ` |
| **Covariance** | `Cov(X,Y) = Î£(xáµ¢âˆ’xÌ„)(yáµ¢âˆ’È³) / (nâˆ’1)` |
| **Pearson Correlation** | `r = Cov(X,Y) / (Ïƒâ‚“ Â· Ïƒáµ§)` |
| **Binomial PMF** | `P(X=k) = C(n,k) Â· páµ Â· (1âˆ’p)â¿â»áµ` |
| **Poisson PMF** | `P(X=k) = (Î»áµ Â· eâ»Î») / k!` |
| **Normal PDF** | `f(x) = (1/Ïƒâˆš2Ï€) Â· e^(âˆ’(xâˆ’Î¼)Â²/2ÏƒÂ²)` |
| **Z-Test Statistic** | `z = (xÌ„ âˆ’ Î¼â‚€) / (Ïƒ/âˆšn)` |
| **T-Test Statistic** | `t = (xÌ„ âˆ’ Î¼â‚€) / (s/âˆšn)` |
| **Confidence Interval** | `xÌ„ Â± z*(Ïƒ/âˆšn)` |

</div>

---

## ğŸ“ Folder Structure

```
ğŸ“‚ Statistics and Probability/
â”‚
â”œâ”€â”€ ğŸ““ 01_intro_to_statistics.ipynb
â”œâ”€â”€ ğŸ““ 02_measures_central_tendency.ipynb
â”œâ”€â”€ ğŸ““ 03_measures_of_dispersion.ipynb
â”œâ”€â”€ ğŸ““ 04_bivariate_analysis.ipynb
â”œâ”€â”€ ğŸ““ 05_probability_fundamentals.ipynb
â”œâ”€â”€ ğŸ““ 06_normal_distribution.ipynb
â”œâ”€â”€ ğŸ““ 07_binomial_distribution.ipynb
â”œâ”€â”€ ğŸ““ 08_poisson_distribution.ipynb
â”œâ”€â”€ ğŸ““ 09_skewness_and_kurtosis.ipynb
â”œâ”€â”€ ğŸ““ 10_central_limit_theorem.ipynb
â”œâ”€â”€ ğŸ““ 11_hypothesis_testing_basics.ipynb
â”œâ”€â”€ ğŸ““ 12_z_test_and_t_test.ipynb
â”œâ”€â”€ ğŸ““ 13_chi_square_test.ipynb
â””â”€â”€ ğŸ“„ README.md
```

---

## ğŸ› ï¸ Tools & Libraries

<div align="center">

| ğŸ“¦ Library | ğŸ¯ Purpose | ğŸ’¡ Key Functions |
|-----------|-----------|-----------------|
| ![NumPy](https://img.shields.io/badge/NumPy-013243?style=flat-square&logo=numpy&logoColor=white) | Numerical computing | `np.mean()`, `np.std()`, `np.random.*` |
| ![Pandas](https://img.shields.io/badge/Pandas-150458?style=flat-square&logo=pandas&logoColor=white) | Data manipulation & summary stats | `df.describe()`, `df.corr()`, `df.cov()` |
| ![Matplotlib](https://img.shields.io/badge/Matplotlib-11557C?style=flat-square) | Static visualizations | `plt.hist()`, `plt.boxplot()` |
| ![Seaborn](https://img.shields.io/badge/Seaborn-4C72B0?style=flat-square) | Statistical visualizations | `sns.distplot()`, `sns.heatmap()` |
| ![SciPy](https://img.shields.io/badge/SciPy-8CAAE6?style=flat-square&logo=scipy&logoColor=white) | Statistical tests | `ttest_ind`, `chi2_contingency`, `norm` |
| ![Statsmodels](https://img.shields.io/badge/Statsmodels-4051B5?style=flat-square) | Advanced statistics | `ztest()`, `OLS()` |

</div>

---

## ğŸš€ Getting Started

```bash
git clone https://github.com/MuhammadZafran33/Data-Science-Course.git
cd "Data-Science-Course/Data Science Full Course By WsCube Tech/Statistics and Probability"
pip install numpy pandas matplotlib seaborn scipy statsmodels jupyter
jupyter notebook
```

[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MuhammadZafran33/Data-Science-Course/)

---

## ğŸ”— Navigation

<div align="center">

| â¬…ï¸ Previous | ğŸ“ You Are Here | â¡ï¸ Next |
|------------|----------------|--------|
| [ğŸŒ Web Scraping](../Web%20Scraping/) | **ğŸ“Š Statistics & Probability** | [ğŸ”¢ NumPy â†’](../NumPy/) |

</div>

---

<div align="center">

[![GitHub](https://img.shields.io/badge/GitHub-MuhammadZafran33-181717?style=for-the-badge&logo=github)](https://github.com/MuhammadZafran33)

<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%"/>

> *"Statistical thinking will one day be as necessary for efficient citizenship as the ability to read and write."*
> **â€” H.G. Wells**

**â­ Star the repo if this helped! â­**

<img src="https://readme-typing-svg.demolab.com?font=Fira+Code&size=13&pause=1000&color=A78BFA&center=true&vCenter=true&width=600&lines=Stats+is+the+foundation+of+all+Data+Science+%F0%9F%9A%80" alt="Footer"/>

</div>
