<div align="center">

<img width="100%" src="https://capsule-render.vercel.app/api?type=waving&color=0:0d0221,40:0a1628,70:1a1035,100:2d1b69&height=240&section=header&text=Statistics%20%26%20Probability&fontSize=52&fontColor=a78bfa&fontAlignY=38&desc=%F0%9F%94%AE%20The%20Mathematical%20Engine%20Behind%20Every%20Data%20Science%20Model&descAlignY=60&descSize=17&animation=fadeIn"/>

<br/>

<p>
  <img src="https://img.shields.io/badge/Module-Statistics%20%26%20Probability-7c3aed?style=for-the-badge&logo=python&logoColor=white"/>
  <img src="https://img.shields.io/badge/Course-WsCube%20Tech%20DS-a78bfa?style=for-the-badge&logo=youtube&logoColor=white"/>
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white"/>
  <img src="https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy&logoColor=white"/>
  <img src="https://img.shields.io/badge/SciPy-8CAAE6?style=for-the-badge&logo=scipy&logoColor=white"/>
</p>

<p>
  <img src="https://img.shields.io/badge/Notebooks-12+-success?style=flat-square"/>
  <img src="https://img.shields.io/badge/Topics-30%2B%20Concepts-blueviolet?style=flat-square"/>
  <img src="https://img.shields.io/badge/Level-Beginner%20%E2%86%92%20Intermediate-orange?style=flat-square"/>
  <img src="https://img.shields.io/badge/Status-Active-brightgreen?style=flat-square"/>
  <img src="https://img.shields.io/github/last-commit/MuhammadZafran33/Data-Science-Course?style=flat-square&color=violet"/>
</p>

<br/>

> ### ğŸ¯ *"Statistics is the grammar of science"* â€” Karl Pearson
>
> This module covers the complete **Statistics & Probability** foundation required for Data Science â€”
> from measures of central tendency all the way to hypothesis testing & probability distributions.

<br/>

</div>

---

## ğŸ“š Table of Contents

| # | Section | Quick Link |
|---|---------|-----------|
| 01 | ğŸ—ºï¸ Module Overview | [Jump](#ï¸-module-overview) |
| 02 | ğŸ§­ Learning Roadmap | [Jump](#-learning-roadmap) |
| 03 | ğŸ“– Topic Deep Dive | [Jump](#-topic-deep-dive) |
| 04 | ğŸ“Š Coverage Charts | [Jump](#-coverage-charts) |
| 05 | ğŸ”¬ Probability Distributions | [Jump](#-probability-distributions-at-a-glance) |
| 06 | ğŸ§ª Hypothesis Testing Guide | [Jump](#-hypothesis-testing-decision-guide) |
| 07 | ğŸ“ Key Formulas Cheatsheet | [Jump](#-key-formulas-cheatsheet) |
| 08 | ğŸ“ Folder Structure | [Jump](#-folder-structure) |
| 09 | ğŸ› ï¸ Tools & Libraries | [Jump](#ï¸-tools--libraries) |
| 10 | ğŸš€ Getting Started | [Jump](#-getting-started) |

---

## ğŸ—ºï¸ Module Overview

<div align="center">

| ğŸ“Œ Attribute | ğŸ“‹ Details |
|-------------|-----------|
| ğŸ“ **Parent Course** | Data Science Full Course â€” WsCube Tech |
| ğŸ“‚ **Module Name** | Statistics & Probability |
| ğŸ“ **Position in Course** | Module 14â€“15 (Foundations before ML) |
| â±ï¸ **Study Duration** | ~2â€“3 Weeks Â· 15+ Hours |
| ğŸ““ **Notebooks** | 12+ Jupyter Notebooks |
| ğŸ¯ **Why It Matters** | Every ML algorithm is built on statistical principles |
| ğŸ”— **Leads To** | EDA â†’ Machine Learning â†’ Model Evaluation |

</div>

---

## ğŸ§­ Learning Roadmap

```mermaid
flowchart TD
    START(["ğŸ“Š START\nStatistics & Probability"])

    START --> A["ğŸ“Œ Introduction to Statistics\nData Â· Sample Â· Population\nTypes of Data"]

    A --> B["ğŸ“ˆ Descriptive Statistics\nSummarize & describe data"]

    B --> B1["ğŸ“ Measures of Central Tendency\nMean Â· Median Â· Mode"]
    B --> B2["ğŸ“ Measures of Dispersion\nRange Â· Variance Â· Std Dev"]
    B --> B3["ğŸ”— Bivariate Analysis\nCovariance Â· Correlation"]

    B1 & B2 & B3 --> C["ğŸ² Probability Theory\nCore concepts & rules"]

    C --> C1["ğŸ° Random Variables\nDiscrete & Continuous"]
    C --> C2["ğŸ“ Probability Distributions\nPDF & CDF"]

    C1 & C2 --> D["ğŸ”” Key Distributions"]
    D --> D1["Normal\nDistribution"]
    D --> D2["Binomial\nDistribution"]
    D --> D3["Poisson\nDistribution"]

    D1 & D2 & D3 --> E["ğŸ“‰ Inferential Statistics"]
    E --> E1["ğŸ”„ Central Limit Theorem"]
    E --> E2["ğŸ“Š Skewness & Kurtosis"]

    E1 & E2 --> F["ğŸ§ª Hypothesis Testing"]
    F --> F1["âš–ï¸ Z-Test\nOne Sample"]
    F --> F2["ğŸ“ T-Test\nStudent's t"]
    F --> F3["ğŸ”² Chi-Square\nTest"]

    F1 & F2 & F3 --> END(["âœ… COMPLETE\nReady for EDA & ML"])

    style START fill:#7c3aed,stroke:none,color:#fff
    style END fill:#059669,stroke:none,color:#fff
    style A fill:#1e1b4b,stroke:#7c3aed,color:#c4b5fd
    style B fill:#1e1b4b,stroke:#7c3aed,color:#c4b5fd
    style C fill:#1e1b4b,stroke:#a78bfa,color:#c4b5fd
    style D fill:#1e1b4b,stroke:#a78bfa,color:#c4b5fd
    style E fill:#1e1b4b,stroke:#7c3aed,color:#c4b5fd
    style F fill:#1e1b4b,stroke:#7c3aed,color:#c4b5fd
    style B1 fill:#2d1b69,stroke:none,color:#e9d5ff
    style B2 fill:#2d1b69,stroke:none,color:#e9d5ff
    style B3 fill:#2d1b69,stroke:none,color:#e9d5ff
    style C1 fill:#2d1b69,stroke:none,color:#e9d5ff
    style C2 fill:#2d1b69,stroke:none,color:#e9d5ff
    style D1 fill:#4c1d95,stroke:none,color:#e9d5ff
    style D2 fill:#4c1d95,stroke:none,color:#e9d5ff
    style D3 fill:#4c1d95,stroke:none,color:#e9d5ff
    style E1 fill:#2d1b69,stroke:none,color:#e9d5ff
    style E2 fill:#2d1b69,stroke:none,color:#e9d5ff
    style F1 fill:#4c1d95,stroke:none,color:#e9d5ff
    style F2 fill:#4c1d95,stroke:none,color:#e9d5ff
    style F3 fill:#4c1d95,stroke:none,color:#e9d5ff
```

---

## ğŸ“– Topic Deep Dive

### ğŸ”· PART 1 â€” Introduction to Statistics

| Topic | Description | Notebook |
|-------|-------------|:--------:|
| ğŸ“Œ What is Statistics? | Definition, uses in data science & real-world examples | `01_intro_statistics.ipynb` |
| ğŸ‘¥ Data, Sample & Population | Difference between population parameters and sample statistics | `01_intro_statistics.ipynb` |
| ğŸ·ï¸ Types of Data | Qualitative (nominal, ordinal) vs Quantitative (discrete, continuous) | `01_intro_statistics.ipynb` |

---

### ğŸ”· PART 2 â€” Descriptive Statistics

#### ğŸ“ Measures of Central Tendency

| Measure | Formula | Best Used When | Notebook |
|---------|---------|---------------|:--------:|
| **Mean** | `Î£x / n` | Symmetric data, no outliers | `02_central_tendency.ipynb` |
| **Median** | Middle value when sorted | Skewed data or outliers present | `02_central_tendency.ipynb` |
| **Mode** | Most frequent value | Categorical data | `02_central_tendency.ipynb` |

#### ğŸ“ Measures of Dispersion

| Measure | Formula | What It Tells You | Notebook |
|---------|---------|------------------|:--------:|
| **Range** | `Max âˆ’ Min` | Total spread of data | `03_dispersion.ipynb` |
| **Variance** | `Î£(xâˆ’Î¼)Â² / n` | Average squared deviation from mean | `03_dispersion.ipynb` |
| **Std Deviation** | `âˆšVariance` | Spread in original units | `03_dispersion.ipynb` |
| **IQR** | `Q3 âˆ’ Q1` | Middle 50% spread, robust to outliers | `03_dispersion.ipynb` |

#### ğŸ”— Bivariate Analysis

| Concept | Range | Interpretation | Notebook |
|---------|-------|---------------|:--------:|
| **Covariance** | `-âˆ to +âˆ` | Direction of linear relationship | `04_bivariate.ipynb` |
| **Pearson Correlation** | `-1 to +1` | Strength + direction of relationship | `04_bivariate.ipynb` |

---

### ğŸ”· PART 3 â€” Probability & Distributions

#### ğŸ² Probability Foundations

| Concept | Key Idea | Notebook |
|---------|---------|:--------:|
| **Random Variable** | Variable whose value is determined by a random experiment | `05_probability.ipynb` |
| **PDF** (Prob. Density Function) | Probability for continuous variables | `05_probability.ipynb` |
| **CDF** (Cumulative Distribution) | Probability that X â‰¤ x | `05_probability.ipynb` |
| **Normal Distribution** | Bell curve â€” the most important distribution in stats | `06_normal_dist.ipynb` |
| **Binomial Distribution** | Success/failure over n trials | `07_binomial_dist.ipynb` |
| **Poisson Distribution** | Count of events in a fixed interval | `08_poisson_dist.ipynb` |
| **Skewness** | Asymmetry of distribution around mean | `09_skewness.ipynb` |

---

### ğŸ”· PART 4 â€” Inferential Statistics & Hypothesis Testing

| Concept | Key Idea | Notebook |
|---------|---------|:--------:|
| **Central Limit Theorem** | Sample means are normally distributed regardless of population shape | `10_CLT.ipynb` |
| **Null Hypothesis (Hâ‚€)** | Default claim â€” no effect or difference exists | `11_hypothesis.ipynb` |
| **Alternate Hypothesis (Hâ‚)** | What we aim to prove â€” effect or difference exists | `11_hypothesis.ipynb` |
| **p-value** | Probability of observing results if Hâ‚€ is true | `11_hypothesis.ipynb` |
| **Level of Significance (Î±)** | Threshold (typically 0.05) to reject Hâ‚€ | `11_hypothesis.ipynb` |
| **Confidence Interval** | Range that contains true parameter with (1âˆ’Î±)% certainty | `11_hypothesis.ipynb` |
| **One-Sample Z-Test** | Test population mean when Ïƒ is known, n â‰¥ 30 | `12_zttest.ipynb` |
| **Student's T-Test** | Test means when Ïƒ unknown or small sample | `12_zttest.ipynb` |
| **Chi-Square Test** | Test independence between categorical variables | `13_chi_square.ipynb` |

---

## ğŸ“Š Coverage Charts

### Content Distribution by Topic

```mermaid
pie title Statistics & Probability â€” Topic Coverage (Concepts)
    "Descriptive Statistics" : 25
    "Probability Theory" : 20
    "Probability Distributions" : 22
    "Inferential Statistics" : 15
    "Hypothesis Testing" : 18
```

### Time Investment Per Section

```mermaid
xychart-beta
    title "Estimated Study Hours per Section"
    x-axis ["Intro to Stats", "Central Tendency", "Dispersion", "Bivariate", "Probability", "Distributions", "CLT & Skewness", "Hypothesis Tests"]
    y-axis "Hours" 0 --> 4
    bar [1, 1.5, 2, 1.5, 2, 3, 2, 3]
    line [1, 1.5, 2, 1.5, 2, 3, 2, 3]
```

### Module Position in Full Course

```mermaid
gantt
    title Module 14-15 Position in WsCube Tech Data Science Course
    dateFormat  X
    axisFormat  Module %s

    section Core Python
    Python Fundamentals         :done,    m1,  1,  4
    Web Scraping                :done,    m2,  4,  5

    section Data Science Intro
    Intro to Data Science       :done,    m3,  5,  6
    Statistics and Probability  :active,  m4,  6,  8

    section Data Layer
    NumPy                       :         m5,  8,  9
    Pandas                      :         m6,  9, 11

    section Visualization
    Matplotlib and Seaborn      :         m7, 11, 13

    section Analysis
    EDA Projects                :         m8, 13, 15

    section ML
    Machine Learning            :         m9, 15, 22
```

---

## ğŸ”¬ Probability Distributions at a Glance

```mermaid
flowchart LR
    subgraph DISCRETE ["ğŸ² Discrete Distributions"]
        direction TB
        B["ğŸ“Š Binomial\nBin(n, p)\nFixed trials,\nSuccess/Fail"]
        P["ğŸ“ˆ Poisson\nPois(Î»)\nEvents per\ninterval"]
    end

    subgraph CONTINUOUS ["ã€°ï¸ Continuous Distributions"]
        direction TB
        N["ğŸ”” Normal\nN(Î¼, ÏƒÂ²)\nBell curve\n68-95-99.7 rule"]
        U["â¬œ Uniform\nU(a, b)\nEqual\nprobability"]
    end

    subgraph USE ["ğŸ“Œ When to Use?"]
        direction TB
        U1["n trials,\np(success)?\nâ†’ Binomial"]
        U2["Count events\nin time/space?\nâ†’ Poisson"]
        U3["Heights, test\nscores, errors?\nâ†’ Normal"]
    end

    DISCRETE --> USE
    CONTINUOUS --> USE

    style B fill:#4c1d95,stroke:none,color:#e9d5ff
    style P fill:#4c1d95,stroke:none,color:#e9d5ff
    style N fill:#1e1b4b,stroke:#7c3aed,color:#c4b5fd
    style U fill:#1e1b4b,stroke:#7c3aed,color:#c4b5fd
    style U1 fill:#2d1b69,stroke:none,color:#e9d5ff
    style U2 fill:#2d1b69,stroke:none,color:#e9d5ff
    style U3 fill:#2d1b69,stroke:none,color:#e9d5ff
```

### Distribution Properties Comparison Table

| Distribution | Type | Parameters | Mean | Variance | Real-World Example |
|-------------|------|-----------|------|----------|-------------------|
| ğŸ”” **Normal** | Continuous | Î¼, Ïƒ | Î¼ | ÏƒÂ² | Heights, IQ scores, measurement errors |
| ğŸ“Š **Binomial** | Discrete | n, p | np | np(1âˆ’p) | Coin flips, pass/fail tests, click-through rates |
| ğŸ“ˆ **Poisson** | Discrete | Î» | Î» | Î» | Calls per hour, bugs per code file, accidents per day |
| â¬œ **Uniform** | Continuous | a, b | (a+b)/2 | (bâˆ’a)Â²/12 | Random number generation, dice rolls |

---

## ğŸ§ª Hypothesis Testing Decision Guide

```mermaid
flowchart TD
    A(["ğŸ§ª Start:\nWhat do you want to test?"]) --> B{"Data type?"}

    B -- "Numerical\n(means)" --> C{"How many\ngroups?"}
    B -- "Categorical\n(frequencies)" --> G["ğŸ”² Chi-Square Test\nIndependence or\ngoodness of fit"]

    C -- "1 group vs\nknown Î¼" --> D{"Sample size\n& Ïƒ known?"}
    C -- "2 independent\ngroups" --> E["ğŸ“ Independent\nSamples T-Test"]
    C -- "1 group\nbefore & after" --> F["ğŸ“ Paired\nT-Test"]

    D -- "nâ‰¥30 &\nÏƒ known" --> H["âš¡ One-Sample\nZ-Test"]
    D -- "n<30 or\nÏƒ unknown" --> I["ğŸ“ One-Sample\nT-Test"]

    H & I & E & F & G --> J(["ğŸ“‹ Compute p-value"])

    J --> K{"p-value < Î±\n(typically 0.05)?"}
    K -- "YES âœ…" --> L(["âœ… Reject Hâ‚€\nResult is Statistically\nSignificant"])
    K -- "NO âŒ" --> M(["âŒ Fail to Reject Hâ‚€\nInsufficient Evidence"])

    style A fill:#7c3aed,stroke:none,color:#fff
    style L fill:#059669,stroke:none,color:#fff
    style M fill:#dc2626,stroke:none,color:#fff
    style J fill:#1e1b4b,stroke:#7c3aed,color:#c4b5fd
    style K fill:#4c1d95,stroke:none,color:#e9d5ff
    style B fill:#2d1b69,stroke:none,color:#e9d5ff
    style C fill:#2d1b69,stroke:none,color:#e9d5ff
    style D fill:#2d1b69,stroke:none,color:#e9d5ff
    style E fill:#1e1b4b,stroke:#a78bfa,color:#c4b5fd
    style F fill:#1e1b4b,stroke:#a78bfa,color:#c4b5fd
    style G fill:#1e1b4b,stroke:#a78bfa,color:#c4b5fd
    style H fill:#1e1b4b,stroke:#a78bfa,color:#c4b5fd
    style I fill:#1e1b4b,stroke:#a78bfa,color:#c4b5fd
```

### Hypothesis Tests Quick-Reference

| Test | Use Case | Condition | Python Function |
|------|---------|-----------|----------------|
| âš¡ **Z-Test** | Test one mean vs known Î¼ | Ïƒ known, n â‰¥ 30 | `statsmodels.stats.weightstats.ztest` |
| ğŸ“ **1-Sample T-Test** | Test one mean vs value | Ïƒ unknown / small n | `scipy.stats.ttest_1samp` |
| ğŸ“ **2-Sample T-Test** | Compare two group means | Independent groups | `scipy.stats.ttest_ind` |
| ğŸ“ **Paired T-Test** | Before vs after comparison | Same group, two measures | `scipy.stats.ttest_rel` |
| ğŸ”² **Chi-Square Test** | Association between categories | Expected freq â‰¥ 5 | `scipy.stats.chi2_contingency` |

---

## ğŸ“ Key Formulas Cheatsheet

<div align="center">

| ğŸ“Œ Concept | ğŸ”¢ Formula |
|-----------|-----------|
| **Population Mean** | `Î¼ = Î£xáµ¢ / N` |
| **Sample Mean** | `xÌ„ = Î£xáµ¢ / n` |
| **Population Variance** | `ÏƒÂ² = Î£(xáµ¢ âˆ’ Î¼)Â² / N` |
| **Sample Variance** | `sÂ² = Î£(xáµ¢ âˆ’ xÌ„)Â² / (nâˆ’1)` |
| **Standard Deviation** | `Ïƒ = âˆšÏƒÂ²` |
| **Z-Score (standardize)** | `z = (x âˆ’ Î¼) / Ïƒ` |
| **Covariance** | `Cov(X,Y) = Î£(xáµ¢âˆ’xÌ„)(yáµ¢âˆ’È³) / (nâˆ’1)` |
| **Pearson Correlation** | `r = Cov(X,Y) / (Ïƒâ‚“ Â· Ïƒáµ§)` |
| **Binomial PMF** | `P(X=k) = C(n,k) Â· páµ Â· (1âˆ’p)â¿â»áµ` |
| **Poisson PMF** | `P(X=k) = (Î»áµ Â· eâ»Î») / k!` |
| **Normal PDF** | `f(x) = (1/Ïƒâˆš2Ï€) Â· e^(âˆ’(xâˆ’Î¼)Â²/2ÏƒÂ²)` |
| **Z-Test Statistic** | `z = (xÌ„ âˆ’ Î¼â‚€) / (Ïƒ/âˆšn)` |
| **T-Test Statistic** | `t = (xÌ„ âˆ’ Î¼â‚€) / (s/âˆšn)` |
| **Confidence Interval** | `xÌ„ Â± z*(Ïƒ/âˆšn)` |

</div>

---

## ğŸ“ Folder Structure

```
ğŸ“‚ Statistics and Probability/
â”‚
â”œâ”€â”€ ğŸ““ 01_intro_to_statistics.ipynb
â”‚   â””â”€â”€ â†’ What is stats Â· Data types Â· Sample vs Population
â”‚
â”œâ”€â”€ ğŸ““ 02_measures_central_tendency.ipynb
â”‚   â””â”€â”€ â†’ Mean Â· Median Â· Mode Â· Weighted Mean
â”‚
â”œâ”€â”€ ğŸ““ 03_measures_of_dispersion.ipynb
â”‚   â””â”€â”€ â†’ Range Â· Variance Â· Std Dev Â· IQR Â· Outliers
â”‚
â”œâ”€â”€ ğŸ““ 04_bivariate_analysis.ipynb
â”‚   â””â”€â”€ â†’ Covariance Â· Pearson Correlation Â· Heatmaps
â”‚
â”œâ”€â”€ ğŸ““ 05_probability_fundamentals.ipynb
â”‚   â””â”€â”€ â†’ Rules Â· Random Variables Â· PDF Â· CDF
â”‚
â”œâ”€â”€ ğŸ““ 06_normal_distribution.ipynb
â”‚   â””â”€â”€ â†’ Bell curve Â· Z-score Â· Empirical Rule (68-95-99.7)
â”‚
â”œâ”€â”€ ğŸ““ 07_binomial_distribution.ipynb
â”‚   â””â”€â”€ â†’ PMF Â· CDF Â· Simulation Â· Visualisation
â”‚
â”œâ”€â”€ ğŸ““ 08_poisson_distribution.ipynb
â”‚   â””â”€â”€ â†’ Rate events Â· Î» parameter Â· Real-world examples
â”‚
â”œâ”€â”€ ğŸ““ 09_skewness_and_kurtosis.ipynb
â”‚   â””â”€â”€ â†’ Positive/Negative skew Â· Transformations
â”‚
â”œâ”€â”€ ğŸ““ 10_central_limit_theorem.ipynb
â”‚   â””â”€â”€ â†’ CLT simulation Â· Sampling distributions
â”‚
â”œâ”€â”€ ğŸ““ 11_hypothesis_testing_basics.ipynb
â”‚   â””â”€â”€ â†’ Hâ‚€ Hâ‚ Â· p-value Â· Î± Â· Type I & II errors
â”‚
â”œâ”€â”€ ğŸ““ 12_z_test_and_t_test.ipynb
â”‚   â””â”€â”€ â†’ One-sample Z Â· One & Two-sample T Â· Scipy
â”‚
â”œâ”€â”€ ğŸ““ 13_chi_square_test.ipynb
â”‚   â””â”€â”€ â†’ Independence test Â· Contingency tables
â”‚
â””â”€â”€ ğŸ“„ README.md
```

---

## ğŸ› ï¸ Tools & Libraries

<div align="center">

| ğŸ“¦ Library | ğŸ¯ Purpose | ğŸ’¡ Key Functions Used |
|-----------|-----------|----------------------|
| ![NumPy](https://img.shields.io/badge/NumPy-013243?style=flat-square&logo=numpy&logoColor=white) | Numerical computing & array operations | `np.mean()`, `np.std()`, `np.random.*` |
| ![Pandas](https://img.shields.io/badge/Pandas-150458?style=flat-square&logo=pandas&logoColor=white) | Data manipulation & summary stats | `df.describe()`, `df.corr()`, `df.cov()` |
| ![Matplotlib](https://img.shields.io/badge/Matplotlib-11557C?style=flat-square) | Static visualizations | `plt.hist()`, `plt.boxplot()`, `plt.scatter()` |
| ![Seaborn](https://img.shields.io/badge/Seaborn-4C72B0?style=flat-square) | Statistical visualizations | `sns.distplot()`, `sns.heatmap()`, `sns.boxplot()` |
| ![SciPy](https://img.shields.io/badge/SciPy-8CAAE6?style=flat-square&logo=scipy&logoColor=white) | Statistical tests | `scipy.stats.norm`, `ttest_ind`, `chi2_contingency` |
| ![Statsmodels](https://img.shields.io/badge/Statsmodels-4051B5?style=flat-square) | Advanced statistics | `ztest()`, `OLS()`, `anova_lm()` |

</div>

---

## ğŸš€ Getting Started

### Clone & Navigate

```bash
git clone https://github.com/MuhammadZafran33/Data-Science-Course.git
cd "Data-Science-Course/Data Science Full Course By WsCube Tech/Statistics and Probability"
```

### Install Dependencies

```bash
pip install numpy pandas matplotlib seaborn scipy statsmodels jupyter
```

### Launch Notebooks

```bash
jupyter notebook
```

> â˜ï¸ **No setup?** Run everything directly in the browser:

<div align="center">

[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MuhammadZafran33/Data-Science-Course/)

</div>

### ğŸ“‹ Recommended Study Order

```mermaid
journey
    title Recommended Learning Path Through This Module
    section Week 1 â€” Descriptive Stats
      Intro to Statistics: 9: Learner
      Central Tendency: 9: Learner
      Measures of Dispersion: 8: Learner
      Bivariate Analysis: 7: Learner
    section Week 2 â€” Probability
      Probability Fundamentals: 8: Learner
      Normal Distribution: 9: Learner
      Binomial Distribution: 8: Learner
      Poisson Distribution: 7: Learner
    section Week 3 â€” Inference
      Skewness and Kurtosis: 7: Learner
      Central Limit Theorem: 8: Learner
      Hypothesis Testing: 7: Learner
      Z-Test and T-Test: 6: Learner
      Chi-Square Test: 6: Learner
```

---

## ğŸ§  Why Statistics Matters for Data Science

```mermaid
mindmap
  root((Statistics\nin Data Science))
    Machine Learning
      Model assumptions
      Feature selection
      Regularization logic
    EDA
      Outlier detection
      Distribution analysis
      Correlation mapping
    A/B Testing
      Hypothesis tests
      Confidence intervals
      Significance levels
    Deep Learning
      Weight initialization
      Batch normalization
      Loss function math
    Data Quality
      Anomaly detection
      Missing value treatment
      Data validation
```

---

## ğŸ”— Navigation

<div align="center">

| â¬…ï¸ Previous Module | ğŸ“ You Are Here | â¡ï¸ Next Module |
|-------------------|----------------|---------------|
| [ğŸŒ Web Scraping](../Web%20Scraping/) | **ğŸ“Š Statistics & Probability** | [ğŸ”¢ NumPy â†’](../NumPy/) |

</div>

---

<div align="center">

<br/>

[![GitHub](https://img.shields.io/badge/GitHub-MuhammadZafran33-181717?style=for-the-badge&logo=github&logoColor=white)](https://github.com/MuhammadZafran33)

<br/>

> *"Statistical thinking will one day be as necessary for efficient citizenship*
> *as the ability to read and write."*
>
> **â€” H.G. Wells**

<br/>

**â­ Found this helpful? Drop a star on the repo â€” it keeps the learning journey going! â­**

<br/>

<img width="100%" src="https://capsule-render.vercel.app/api?type=waving&color=0:2d1b69,50:1e1b4b,100:0d0221&height=140&section=footer"/>

</div>
